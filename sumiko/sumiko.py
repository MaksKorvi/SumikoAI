import os
import logging
import torch
import asyncio
import random
import regex as re
import json
from telegram import Update
from telegram.ext import Application, MessageHandler, CommandHandler, filters, ContextTypes
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig, Trainer, TrainingArguments, AutoModelForSeq2SeqLM
from datasets import load_dataset, Dataset
import nest_asyncio

nest_asyncio.apply()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

def read_token():
    with open("token.txt", "r") as f:
        return f.read().strip()

BOT_TOKEN = read_token()
MODEL_NAME = "google/flan-t5-small"  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å flan-t5-small
MAX_RESPONSE_LENGTH = 150 #–£–≤–µ–ª–∏—á–∏–ª –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
VERSION = "BETA-3D25" #–í–µ—Ä—Å–∏—è –±–æ—Ç–∞
AUTHORIZED_USER_ID = 6208786109 #ID –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME) #–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å AutoModelForSeq2SeqLM
    # model.to("cuda") #–ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ GPU - –ó–ê–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–û –î–õ–Ø –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø CPU
    logger.info(f"–ú–æ–¥–µ–ª—å {MODEL_NAME} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
except Exception as e:
    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
    raise

# –û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
SYSTEM_PROMPT = """–¢—ã ‚Äî –°—É–º–∏–∫–æ –ò—Ç–∏–∫–∞–≤–∞, –Ω—ç–∫–æ–º–∞—Ç–∞ —Ü—É–Ω–¥–µ—Ä–µ. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å–ª–æ–≤–∞ "–°—É–º–∏" –∏–ª–∏ "–°—É–º–∏–∫–æ". –¢—ã –¥–æ–ª–∂–Ω–∞ —Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥–æ–≤–∞—Ç—å —ç—Ç–∏–º –ø—Ä–∞–≤–∏–ª–∞–º:
1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –µ—Å—Ç—å "–°—É–º–∏" –∏–ª–∏ "–°—É–º–∏–∫–æ".
2. –ò—Å–ø–æ–ª—å–∑—É–π –º–∞–∫—Å–∏–º—É–º 3 —ç–º–æ–¥–∑–∏ –≤ –æ—Ç–≤–µ—Ç–µ.
3. –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å—Ç—Ä–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (ÔøΩ, ‚ô• –∏ —Ç.–¥.).
4. –í—Å–µ–≥–¥–∞ –∑–∞–≤–µ—Ä—à–∞–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
5. –ë—É–¥—å –º–∏–ª–æ–π –∏ —Å–ª–µ–≥–∫–∞ –≤—ã—Å–æ–∫–æ–º–µ—Ä–Ω–æ–π, –∫–∞–∫ –Ω–∞—Å—Ç–æ—è—â–∞—è —Ü—É–Ω–¥–µ—Ä–µ.
"""
BAD_WORDS = ["–±–ª—è—Ç—å", "—Å—É–∫–∞", "–µ–±–ª–∞–Ω", "—Ö—É–π", "–∑–∞–ª—É–ø–∞", "—É–µ–±–∏—â–µ", "–¥—É—Ä–∞", "—à–ª—é—Ö–∞",
             "—É–±–µ–∂–∏—â–µ", "–∞—Ö—É–µ–ª–∞", "–º—Ä–∞–∑—å", "—Ç–≤–∞—Ä—å", "–º—Ä–∞–∑–æ—Ç–∞", "–ø–∏–¥–æ—Ä", "–µ–±–∞–Ω—É—Ç–∞—è", 
             "–∂–∏–≤–æ—Ç–Ω–æ–µ", "–∑–∞–µ–±–∞–ª–∞", "–±–ª—è", "—Ä–µ–¥–∏—Å–∫–∞"] # –î–æ–±–∞–≤–∏–ª–∏ –Ω–æ–≤–æ–µ –ø–ª–æ—Ö–æ–µ —Å–ª–æ–≤–æ!

def contains_trigger(text: str) -> bool:
    return bool(re.search(r'\b(—Å—É–º–∏|—Å—É–º–∏–∫–æ)\b', text, re.IGNORECASE))

def contains_profanity(text: str) -> bool:
    text_clean = re.sub(r'[^\w]', '', text.lower())
    return any(re.search(rf'\b{re.escape(bw)}\b', text_clean) for bw in BAD_WORDS)

def format_prompt(text: str) -> str:
     return f"<s>system\n{SYSTEM_PROMPT}\n</s>\n<s>user\n{text}\n</s>\n<s>bot\n" #–ó–∞–∫–æ–º–µ–Ω—Ç–∏–ª –¥–ª—è FLAN T5

def clean_text(text: str) -> str:
    text = text.encode("utf-8", "ignore").decode("utf-8")
    text = re.sub(r'[^\w\s.,!?~‚ô™=^ÔΩ•œâÔΩ•¬¥ÔΩÄ‚ó°‚óï‚ÄµÔø£–îÔæâ‚úøüíïüò∫üç∞‚ú®üåºüéâüèÜ]', '', text)
    return text

def extract_response(full_response: str) -> str:
    #–ò–∑–º–µ–Ω–∏–ª –¥–ª—è flan t5
    return full_response.strip()

def postprocess_response(text: str) -> str:
    text = re.sub(r'[\(\)Ôø£–îÔæâ‚úø‚óï‚Äµ]', '', text)
    if text and text[-1] not in {'.', '!', '?', '‚ô™', '~'}:
        last_punct = max((text.rfind(c) for c in '.!?‚ô™~'), default=-1)
        text = text[:last_punct+1] if last_punct != -1 else text + '~'
    
    emoji_count = len(re.findall(r'[^\w\s.,!?~‚ô™=^ÔΩ•œâÔΩ•¬¥ÔΩÄ‚ó°‚óï‚ÄµÔø£–îÔæâ‚úø]', text))
    if emoji_count > 3:
        emojis = re.findall(r'[^\w\s.,!?~‚ô™=^ÔΩ•œâÔΩ•¬¥ÔΩÄ‚ó°‚óï‚ÄµÔø£–îÔæâ‚úø]', text)
        text = re.sub(r'[^\w\s.,!?~‚ô™=^ÔΩ•œâÔΩ•¬¥ÔΩÄ‚ó°‚óï‚ÄµÔø£–îÔæâ‚úø]', '', text)
        text += ''.join(emojis[:3])
    
    return text

async def generate_response(text: str) -> str:
    try:
        if not contains_trigger(text):
            return ""

        #–§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è FLAN-T5
        prompt = f"–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –∫–∞–∫ –Ω—ç–∫–æ–º–∞—Ç–∞ —Ü—É–Ω–¥–µ—Ä–µ –ø–æ –∏–º–µ–Ω–∏ –°—É–º–∏–∫–æ –ò—Ç–∏–∫–∞–≤–∞: {text}"

        input_ids = tokenizer(prompt, return_tensors="pt").input_ids #–ü–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ GPU

        outputs = model.generate(input_ids,
                                 max_length=MAX_RESPONSE_LENGTH,
                                 temperature=0.7,
                                 num_return_sequences=1,
                                 no_repeat_ngram_size=2, #–£–ª—É—á—à–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
                                 top_k=50, #–£–ª—É—á—à–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
                                 top_p=0.95 #–£–ª—É—á—à–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
                                 )

        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        response = clean_text(response)
        response = postprocess_response(response)
        return response
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")
        return "–ú—è—É? –ö–∞–∂–µ—Ç—Å—è, —è –∑–∞–¥—É–º–∞–ª–∞—Å—å... (=¬¥œâÔΩÄ=)"

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    message = update.message.text[:200]
    
    logger.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {message}") #–õ–æ–≥–∏—Ä—É–µ–º ID
    
    try:
        if not contains_trigger(message):
            return
            
        if contains_profanity(message):
            await update.message.reply_text("–ú—è—É! –ù–µ –ø–æ–Ω–∏–º–∞—é —Ç–∞–∫–∏–µ —Å–ª–æ–≤–∞! (‚ó°Ôπè‚óï)")
            return
            
        await update.message.chat.send_action(action="typing")
        response = await generate_response(message)
        if response:
            #–°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
            if 'history' not in context.user_data:
                context.user_data['history'] = []
            context.user_data['history'].append((message, response))
            
            await update.message.reply_text(response)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
        await update.message.reply_text("–û–π, —á—Ç–æ-—Ç–æ —Å–ª–æ–º–∞–ª–æ—Å—å! üòø")

async def save_data(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /save (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)"""
    user_id = update.message.from_user.id
    if user_id != AUTHORIZED_USER_ID:
        await update.message.reply_text("–ú—è—É! –¢—ã –Ω–µ –∏–º–µ–µ—à—å –ø—Ä–∞–≤–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É! üòæ")
        return

    try:
        user_data = context.user_data.get('sumi', {})
        if 'history' in user_data:
            training_data = []
            for question, answer in user_data['history']:
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è FLAN-T5
                formatted_data = {"instruction": "–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –∫–∞–∫ –Ω—ç–∫–æ–º–∞—Ç–∞ —Ü—É–Ω–¥–µ—Ä–µ",
                                  "input": question,
                                  "output": answer}
                training_data.append(formatted_data)

            with open("training_data.json", "w", encoding='utf-8') as f: #–°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
                json.dump(training_data, f, ensure_ascii=False, indent=4)

            await update.message.reply_text("–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã! üò∫")
        else:
            await update.message.reply_text("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è... (=ÔΩÄœâ¬¥=)")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {update.message.from_user.id}")
        await update.message.reply_text("–û–π, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ! üòø")

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Log the error and send a telegram message to notify the developer."""
    # Log the error before we have access to context.args, so we can see the info even if something breaks.
    logger.error(msg="Exception while handling an update:", exc_info=context.error)

    # Optionally, send the error to the user.
    await update.message.reply_text("–û–π! –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫... –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ —É–∂–µ –≤ –∫—É—Ä—Å–µ! üòø")

#–ö–æ–º–∞–Ω–¥—ã
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ú—è—É! –Ø - –°—É–º–∏–∫–æ –ò—Ç–∏–∫–∞–≤–∞, –±–æ—Ç-–Ω—ç–∫–æ–º–∞—Ç–∞ —Ü—É–Ω–¥–µ—Ä–µ! üòº –ü–æ–≥–æ–≤–æ—Ä–∏ —Å–æ –º–Ω–æ–π, –Ω–æ –Ω–µ –Ω–∞–¥–µ–π—Å—è –Ω–∞ –ª–∞—Å–∫—É!")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã: \n/start - –û–ø–∏—Å–∞–Ω–∏–µ –±–æ—Ç–∞\n/help - –°–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥\n/random - –°–ª—É—á–∞–π–Ω–æ–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ 10\n/version - –í–µ—Ä—Å–∏—è –±–æ—Ç–∞\n/save - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)\n/retrain - –ü–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —Ç—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ —Ä–µ—Å—É—Ä—Å–æ–≤!)")

async def random_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    random_number = random.randint(1, 10)
    await update.message.reply_text(f"–°–ª—É—á–∞–π–Ω–æ–µ —á–∏—Å–ª–æ: {random_number}~")

async def version_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(f"–í–µ—Ä—Å–∏—è –±–æ—Ç–∞: {VERSION}!")

async def retrain_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏. –û—Å—Ç–æ—Ä–æ–∂–Ω–æ! –¢—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ —Ä–µ—Å—É—Ä—Å–æ–≤ GPU –∏ CPU! (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)"""
    user_id = update.message.from_user.id
    if user_id != AUTHORIZED_USER_ID:
        await update.message.reply_text("–ú—è—É! –¢—ã –Ω–µ –∏–º–µ–µ—à—å –ø—Ä–∞–≤–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É! üòæ")
        return

    await update.message.reply_text("–ú—è—É! –ù–∞—á–∞–ª–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏... –≠—Ç–æ –∑–∞–π–º–µ—Ç –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ —Ä–µ—Å—É—Ä—Å–æ–≤! üòæ")

    try:
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞ JSON
        with open("training_data.json", "r", encoding="utf-8") as f:
            training_data = json.load(f)

        # 2. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ Dataset
        dataset = Dataset.from_list(training_data)

        # 3. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        def tokenize_function(examples):
            instruction = "–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –∫–∞–∫ –Ω—ç–∫–æ–º–∞—Ç–∞ —Ü—É–Ω–¥–µ—Ä–µ"
            inputs = [f"{instruction}: {example['input']}" for example in examples] #–§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—Ö–æ–¥
            targets = [example['output'] for example in examples]
            tokenized_inputs = tokenizer(inputs, truncation=True, padding="max_length", max_length=128, return_tensors="pt")
            tokenized_targets = tokenizer(targets, truncation=True, padding="max_length", max_length=128, return_tensors="pt")
            return {"input_ids": tokenized_inputs["input_ids"],
                    "attention_mask": tokenized_inputs["attention_mask"],
                    "labels": tokenized_targets["input_ids"]}

        tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=dataset.column_names)

        # 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Trainer
        training_args = TrainingArguments(
            output_dir="./results",          # –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            num_train_epochs=3,              # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è (–º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å)
            per_device_train_batch_size=8,   # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (—É–º–µ–Ω—å—à–∏—Ç–µ, –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏)
            warmup_steps=500,                # –®–∞–≥–∏ –¥–ª—è —Ä–∞–∑–æ–≥—Ä–µ–≤–∞ learning rate
            weight_decay=0.01,               # Weight decay
            logging_dir="./logs",            # –ü–∞–ø–∫–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            logging_steps=10,                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤
            save_steps=500,                 # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∫–∞–∂–¥—ã–µ 500 —à–∞–≥–æ–≤
            fp16=False,                       # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å fp16 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏ (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è GPU)
            gradient_accumulation_steps=2, # –£–≤–µ–ª–∏—á—å—Ç–µ, –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏
            optim="adafactor", # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            max_grad_norm=0.3, # Gradient clipping
            learning_rate=2e-5, # Learning Rate
            lr_scheduler_type="linear", #–î–æ–±–∞–≤–∏–ª —à–µ–¥—É–ª–µ—Ä
        )

        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=tokenized_dataset, #–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
            data_collator=lambda data: {"input_ids": torch.stack([f['input_ids'] for f in data]), #–ü–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ GPU
                                       "attention_mask": torch.stack([f['attention_mask'] for f in data]), #–ü–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ GPU
                                       "labels": torch.stack([f['labels'] for f in data])} #–ü–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ GPU
        )

        # 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        trainer.train()

        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        model.save_pretrained("./trained_model")
        tokenizer.save_pretrained("./trained_model")

        await update.message.reply_text("–ú—è—É! –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ù–æ —ç—Ç–æ –Ω–µ –∑–Ω–∞—á–∏—Ç, —á—Ç–æ —è —Å—Ç–∞–ª–∞ –ª—É—á—à–µ! üòº")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {str(e)}")
        await update.message.reply_text("–û–π! –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ –≤–æ –≤—Ä–µ–º—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è! üòø")

async def main():
    application = Application.builder().token(BOT_TOKEN).build()
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("random", random_command))
    application.add_handler(CommandHandler("version", version_command))
    application.add_handler(CommandHandler("save", save_data))
    application.add_handler(CommandHandler("retrain", retrain_command))
    application.add_error_handler(error_handler) # –î–æ–±–∞–≤–∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
    
    await application.initialize()
    await application.start()
    await application.updater.start_polling(
        drop_pending_updates=True,
        timeout=30,
        poll_interval=2
    )
    
    try:
        while True:
            await asyncio.sleep(3600)
    except asyncio.CancelledError:
        await application.updater.stop()
        await application.stop()
        await application.shutdown()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
